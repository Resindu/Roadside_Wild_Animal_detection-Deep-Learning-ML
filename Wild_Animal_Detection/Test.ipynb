{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:46:01.790779Z",
     "start_time": "2025-03-18T12:46:01.464145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.feature import hog, graycomatrix, graycoprops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tqdm import tqdm"
   ],
   "id": "ad1ef9cd1e966cc0",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T03:46:32.027560Z",
     "start_time": "2025-03-17T03:46:32.025803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# # Load dataset from directory\n",
    "# def load_dataset(preprocessed_img_dir, img_size=(224, 224)):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "\n",
    "    # class_mapping = {'animals': 1, 'non-animals': 0}\n",
    "\n",
    "    # for folder in os.listdir(preprocessed_img_dir):\n",
    "    #     folder_path = os.path.join(preprocessed_img_dir, folder)\n",
    "    #     if os.path.isdir(folder_path) and folder in class_mapping:\n",
    "    #         label = class_mapping[folder]\n",
    "    #         print(f\"Assigning label {label} to folder {folder}\")\n",
    "    # \n",
    "    #         for img_name in os.listdir(folder_path):\n",
    "    #             img_path = os.path.join(folder_path, img_name)\n",
    "    #             img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    #             if img is None:\n",
    "    #                 print(f\"Failed to load image: {img_path}\")\n",
    "    #                 continue\n",
    "    #             img = cv2.resize(img, img_size)\n",
    "    #             images.append(img / 255.0)  # Normalize\n",
    "    #             labels.append(label)\n",
    "\n",
    "    # print(f\"Total images loaded: {len(images)}\")\n",
    "    # print(f\"Unique classes in labels: {np.unique(labels)}\")\n",
    "    # return np.array(images), np.array(labels)\n",
    "\n",
    "\n"
   ],
   "id": "d102bae1f0d0f8ea",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T03:46:32.036110Z",
     "start_time": "2025-03-17T03:46:32.033988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# \n",
    "# # Load dataset from directory\n",
    "# def load_dataset(preprocessed_img_dir, img_size=(224, 224)):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "# \n",
    "#     class_mapping = {'animals': 1, 'non-animals': 0}\n",
    "# \n",
    "#     # Iterate over the top-level folders (animals, non-animals)\n",
    "#     for folder in os.listdir(preprocessed_img_dir):\n",
    "#         folder_path = os.path.join(preprocessed_img_dir, folder)\n",
    "#         if os.path.isdir(folder_path) and folder in class_mapping:\n",
    "#             label = class_mapping[folder]\n",
    "#             print(f\"Assigning label {label} to folder {folder}\")\n",
    "# \n",
    "#             # Iterate through subdirectories (e.g., deer, rabbit, etc.)\n",
    "#             for subfolder in os.listdir(folder_path):\n",
    "#                 subfolder_path = os.path.join(folder_path, subfolder)\n",
    "#                 if os.path.isdir(subfolder_path):\n",
    "#                     print(f\"Processing subfolder: {subfolder}\")\n",
    "# \n",
    "#                     # Iterate through images in each subfolder\n",
    "#                     for img_name in os.listdir(subfolder_path):\n",
    "#                         img_path = os.path.join(subfolder_path, img_name)\n",
    "#                         \n",
    "#                         # Skip non-image files and directories\n",
    "#                         if os.path.isdir(img_path) or not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "#                             continue\n",
    "#                         \n",
    "#                         # Load the image in grayscale\n",
    "#                         img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "#                         if img is None:\n",
    "#                             print(f\"Failed to load image: {img_path}\")\n",
    "#                             continue\n",
    "#                         img = cv2.resize(img, img_size)\n",
    "#                         images.append(img / 255.0)  # Normalize\n",
    "#                         labels.append(label)\n",
    "# \n",
    "#     print(f\"Total images loaded: {len(images)}\")\n",
    "#     print(f\"Unique classes in labels: {np.unique(labels)}\")\n",
    "#     return np.array(images), np.array(labels)\n"
   ],
   "id": "368c56a7b22ec3c8",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T03:46:32.042366Z",
     "start_time": "2025-03-17T03:46:32.039936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# \n",
    "# # Load dataset from directory\n",
    "# def load_dataset(preprocessed_img_dir, img_size=(224, 224)):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "# \n",
    "#     class_mapping = {'animals': 1, 'non-animals': 0}\n",
    "# \n",
    "#     # Iterate over the top-level folders (animals, non-animals)\n",
    "#     for folder in os.listdir(preprocessed_img_dir):\n",
    "#         folder_path = os.path.join(preprocessed_img_dir, folder)\n",
    "#         if os.path.isdir(folder_path):\n",
    "#             print(f\"Found folder: {folder}\")  # Debugging: check folder name\n",
    "# \n",
    "#             if folder in class_mapping:\n",
    "#                 label = class_mapping[folder]\n",
    "#                 print(f\"Assigning label {label} to folder {folder}\")\n",
    "# \n",
    "#                 # Iterate through subdirectories (e.g., deer, rabbit, etc.)\n",
    "#                 for subfolder in os.listdir(folder_path):\n",
    "#                     subfolder_path = os.path.join(folder_path, subfolder)\n",
    "#                     if os.path.isdir(subfolder_path):\n",
    "#                         print(f\"Processing subfolder: {subfolder}\")  # Debugging: check subfolder name\n",
    "# \n",
    "#                         # Iterate through images in each subfolder\n",
    "#                         for img_name in os.listdir(subfolder_path):\n",
    "#                             img_path = os.path.join(subfolder_path, img_name)\n",
    "#                             \n",
    "#                             # Skip non-image files and directories\n",
    "#                             if os.path.isdir(img_path) or not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "#                                 continue\n",
    "#                             \n",
    "#                             # Load the image in grayscale\n",
    "#                             img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "#                             if img is None:\n",
    "#                                 print(f\"Failed to load image: {img_path}\")\n",
    "#                                 continue\n",
    "#                             img = cv2.resize(img, img_size)\n",
    "#                             images.append(img / 255.0)  # Normalize\n",
    "#                             labels.append(label)\n",
    "# \n",
    "#     print(f\"Total images loaded: {len(images)}\")\n",
    "#     print(f\"Unique classes in labels: {np.unique(labels)}\")\n",
    "#     return np.array(images), np.array(labels)\n"
   ],
   "id": "30e87e08ed88464b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T06:50:36.662305Z",
     "start_time": "2025-03-17T06:50:36.636320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# \n",
    "# def load_dataset(preprocessed_img_dir, img_size=(224, 224),sample_fraction=0.1):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "# \n",
    "#     class_mapping = {'animals': 1, 'non-animals': 0}\n",
    "# \n",
    "#     for folder in os.listdir(preprocessed_img_dir):\n",
    "#         folder_path = os.path.join(preprocessed_img_dir, folder)\n",
    "#         \n",
    "#         if os.path.isdir(folder_path):\n",
    "#             label = class_mapping.get(folder)\n",
    "#             \n",
    "#             # Check if the folder is either 'animals' or 'non-animals' (no need for subfolders)\n",
    "#             if label is not None:\n",
    "#                 print(f\"Assigning label {label} to folder {folder}\")\n",
    "# \n",
    "#                 # If it's the 'non-animals' folder, treat all images directly inside it\n",
    "#                 if folder == 'non-animals':\n",
    "#                     for img_name in os.listdir(folder_path):\n",
    "#                         img_path = os.path.join(folder_path, img_name)\n",
    "#                         img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "#                         if img is None:\n",
    "#                             print(f\"Failed to load image: {img_path}\")\n",
    "#                             continue\n",
    "#                         img = cv2.resize(img, img_size)\n",
    "#                         images.append(img / 255.0)  # Normalize\n",
    "#                         labels.append(label)\n",
    "#                 \n",
    "#                 # If it's the 'animals' folder, process its subfolders (e.g., 'cats', 'dogs', etc.)\n",
    "#                 elif folder == 'animals':\n",
    "#                     for subfolder in os.listdir(folder_path):\n",
    "#                         subfolder_path = os.path.join(folder_path, subfolder)\n",
    "#                         if os.path.isdir(subfolder_path):\n",
    "#                             for img_name in os.listdir(subfolder_path):\n",
    "#                                 img_path = os.path.join(subfolder_path, img_name)\n",
    "#                                 img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "#                                 if img is None:\n",
    "#                                     print(f\"Failed to load image: {img_path}\")\n",
    "#                                     continue\n",
    "#                                 img = cv2.resize(img, img_size)\n",
    "#                                 images.append(img / 255.0)  # Normalize\n",
    "#                                 labels.append(label)\n",
    "# \n",
    "#     print(f\"Total images loaded: {len(images)}\")\n",
    "#     print(f\"Unique classes in labels: {np.unique(labels)}\")\n",
    "#     return np.array(images), np.array(labels)\n"
   ],
   "id": "1907b9eb56ae0f1b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:46:09.153553Z",
     "start_time": "2025-03-18T12:46:09.135963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def load_dataset(preprocessed_img_dir, img_size=(224, 224), sample_fraction=0.3):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    class_mapping = {'animals': 1, 'non-animals': 0}\n",
    "\n",
    "    for folder in os.listdir(preprocessed_img_dir):\n",
    "        folder_path = os.path.join(preprocessed_img_dir, folder)\n",
    "\n",
    "        if os.path.isdir(folder_path) and folder in class_mapping:\n",
    "            label = class_mapping[folder]\n",
    "            print(f\"Assigning label {label} to folder {folder}\")\n",
    "\n",
    "            img_paths = []\n",
    "\n",
    "            # If it's an animal category, process subfolders\n",
    "            for subfolder in [os.path.join(folder_path, sf) for sf in os.listdir(folder_path)]:\n",
    "                if os.path.isdir(subfolder):\n",
    "                    img_paths.extend([os.path.join(subfolder, img) for img in os.listdir(subfolder)])\n",
    "            \n",
    "            # If it's 'non-animals', process files directly inside the folder\n",
    "            if not img_paths:\n",
    "                img_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path)]\n",
    "\n",
    "            sampled_paths = random.sample(img_paths, int(len(img_paths) * sample_fraction))\n",
    "\n",
    "            for img_path in sampled_paths:\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    print(f\"Failed to load image: {img_path}\")\n",
    "                    continue\n",
    "                img = cv2.resize(img, img_size)\n",
    "                images.append(img / 255.0)  # Normalize\n",
    "                labels.append(label)\n",
    "\n",
    "    print(f\"Total images loaded: {len(images)}\")\n",
    "    print(f\"Unique classes in labels: {np.unique(labels)}\")\n",
    "    return np.array(images), np.array(labels)\n"
   ],
   "id": "77a9dc8ecb05303d",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:48:14.111648Z",
     "start_time": "2025-03-18T12:48:14.087669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract HOG features\n",
    "def extract_hog_features(images):\n",
    "    hog_features = []\n",
    "    for img in tqdm(images, desc=\"Extracting HOG features\"):\n",
    "        features = hog(img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "        hog_features.append(features)\n",
    "    return np.array(hog_features)\n",
    "\n",
    "# Extract GLCM features\n",
    "def extract_glcm_features(images):\n",
    "    glcm_features = []\n",
    "    for img in tqdm(images, desc=\"Extracting GLCM features\"):\n",
    "        glcm = graycomatrix((img * 255).astype(np.uint8), distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "        contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "        dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "        homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "        correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "        glcm_features.append([contrast, dissimilarity, homogeneity, energy, correlation])\n",
    "    return np.array(glcm_features)\n"
   ],
   "id": "5662ad50784b10a4",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T06:51:09.705993Z",
     "start_time": "2025-03-17T06:51:09.696201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def load_dataset(preprocessed_img_dir, img_size=(224, 224), sample_fraction=0.3):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    class_mapping = {'animals': 1, 'non-animals': 0}\n",
    "\n",
    "    for folder in os.listdir(preprocessed_img_dir):\n",
    "        folder_path = os.path.join(preprocessed_img_dir, folder)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            label = class_mapping.get(folder)\n",
    "            \n",
    "            # Check if the folder is either 'animals' or 'non-animals' (no need for subfolders)\n",
    "            if label is not None:\n",
    "                print(f\"Assigning label {label} to folder {folder}\")\n",
    "\n",
    "                # If it's the 'non-animals' folder, treat all images directly inside it\n",
    "                if folder == 'non-animals':\n",
    "                    img_paths = [os.path.join(folder_path, img_name) for img_name in os.listdir(folder_path)]\n",
    "                    sampled_paths = random.sample(img_paths, int(len(img_paths) * sample_fraction))\n",
    "\n",
    "                    for img_path in sampled_paths:\n",
    "                        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                        if img is None:\n",
    "                            print(f\"Failed to load image: {img_path}\")\n",
    "                            continue\n",
    "                        img = cv2.resize(img, img_size)\n",
    "                        images.append(img / 255.0)  # Normalize\n",
    "                        labels.append(label)\n",
    "                \n",
    "                # If it's the 'animals' folder, process its subfolders (e.g., 'cats', 'dogs', etc.)\n",
    "                elif folder == 'animals':\n",
    "                    for subfolder in os.listdir(folder_path):\n",
    "                        subfolder_path = os.path.join(folder_path, subfolder)\n",
    "                        if os.path.isdir(subfolder_path):\n",
    "                            img_paths = [os.path.join(subfolder_path, img_name) for img_name in os.listdir(subfolder_path)]\n",
    "                            sampled_paths = random.sample(img_paths, int(len(img_paths) * sample_fraction))\n",
    "\n",
    "                            for img_path in sampled_paths:\n",
    "                                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                                if img is None:\n",
    "                                    print(f\"Failed to load image: {img_path}\")\n",
    "                                    continue\n",
    "                                img = cv2.resize(img, img_size)\n",
    "                                images.append(img / 255.0)  # Normalize\n",
    "                                labels.append(label)\n",
    "\n",
    "    print(f\"Total images loaded: {len(images)}\")\n",
    "    print(f\"Unique classes in labels: {np.unique(labels)}\")\n",
    "    return np.array(images), np.array(labels)\n"
   ],
   "id": "cb39eaafe854dfa3",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:46:59.817047Z",
     "start_time": "2025-03-18T12:46:25.558913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "preprocessed_img_dir = '/Users/resindunavoda/PycharmProjects/Wild_Animal_Detection/Dataset/Output'\n",
    "X, y = load_dataset(preprocessed_img_dir)\n",
    "\n"
   ],
   "id": "57096aefee22388e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning label 0 to folder non-animals\n",
      "Assigning label 1 to folder animals\n",
      "Failed to load image: /Users/resindunavoda/PycharmProjects/Wild_Animal_Detection/Dataset/Output/animals/deer/bear\n",
      "Total images loaded: 8062\n",
      "Unique classes in labels: [0 1]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:47:47.742104Z",
     "start_time": "2025-03-18T12:47:27.444731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Check class balance\n",
    "print(f\"Training class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Testing class distribution: {np.bincount(y_test)}\")"
   ],
   "id": "9efc29d9768ec436",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class distribution: [3851 2598]\n",
      "Testing class distribution: [963 650]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:47:59.552974Z",
     "start_time": "2025-03-18T12:47:59.545403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_class_distribution(y):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(\"Class distribution:\", dict(zip(unique, counts)))"
   ],
   "id": "f3a5f9d4807f947",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:48:02.312945Z",
     "start_time": "2025-03-18T12:48:02.297572Z"
    }
   },
   "cell_type": "code",
   "source": "check_class_distribution(y)\n",
   "id": "445d236c9ab40a60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: {np.int64(0): np.int64(4814), np.int64(1): np.int64(3248)}\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:51:43.065121Z",
     "start_time": "2025-03-18T12:48:25.164147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# HOG + SVM pipeline\n",
    "#Histogram of Oriented Gradients\n",
    "X_train_hog = extract_hog_features(X_train)\n",
    "X_test_hog = extract_hog_features(X_test)\n",
    "\n",
    "svm = SVC(kernel='linear', C=1.0)\n",
    "svm.fit(X_train_hog, y_train)\n",
    "y_pred_svm = svm.predict(X_test_hog)\n",
    "\n",
    "print(\"\\nSVM with HOG Features\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm) * 100:.2f}%\")\n",
    "\n",
    "\n"
   ],
   "id": "d8985a4f1ccb7c5f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting HOG features: 100%|██████████| 6449/6449 [01:03<00:00, 101.79it/s]\n",
      "Extracting HOG features: 100%|██████████| 1613/1613 [00:15<00:00, 104.54it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[28]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      6\u001B[39m svm = SVC(kernel=\u001B[33m'\u001B[39m\u001B[33mlinear\u001B[39m\u001B[33m'\u001B[39m, C=\u001B[32m1.0\u001B[39m)\n\u001B[32m      7\u001B[39m svm.fit(X_train_hog, y_train)\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m y_pred_svm = \u001B[43msvm\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test_hog\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mSVM with HOG Features\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     11\u001B[39m \u001B[38;5;28mprint\u001B[39m(classification_report(y_test, y_pred_svm))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Wild_Animal_Detection/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:822\u001B[39m, in \u001B[36mBaseSVC.predict\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m    820\u001B[39m     y = np.argmax(\u001B[38;5;28mself\u001B[39m.decision_function(X), axis=\u001B[32m1\u001B[39m)\n\u001B[32m    821\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m822\u001B[39m     y = \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    823\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.classes_.take(np.asarray(y, dtype=np.intp))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Wild_Animal_Detection/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:438\u001B[39m, in \u001B[36mBaseLibSVM.predict\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m    436\u001B[39m X = \u001B[38;5;28mself\u001B[39m._validate_for_predict(X)\n\u001B[32m    437\u001B[39m predict = \u001B[38;5;28mself\u001B[39m._sparse_predict \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sparse \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m._dense_predict\n\u001B[32m--> \u001B[39m\u001B[32m438\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Wild_Animal_Detection/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:457\u001B[39m, in \u001B[36mBaseLibSVM._dense_predict\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m    449\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    450\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mX.shape[1] = \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m should be equal to \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    451\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mthe number of samples at training time\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    452\u001B[39m             % (X.shape[\u001B[32m1\u001B[39m], \u001B[38;5;28mself\u001B[39m.shape_fit_[\u001B[32m0\u001B[39m])\n\u001B[32m    453\u001B[39m         )\n\u001B[32m    455\u001B[39m svm_type = LIBSVM_IMPL.index(\u001B[38;5;28mself\u001B[39m._impl)\n\u001B[32m--> \u001B[39m\u001B[32m457\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlibsvm\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    458\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    459\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msupport_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    460\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msupport_vectors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    461\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_n_support\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    462\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dual_coef_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    463\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_intercept_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    464\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_probA\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    465\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_probB\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    466\u001B[39m \u001B[43m    \u001B[49m\u001B[43msvm_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43msvm_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    467\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkernel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    468\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdegree\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdegree\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    469\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcoef0\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcoef0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    470\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgamma\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_gamma\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    471\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_size\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcache_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    472\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T04:48:55.372953Z",
     "start_time": "2025-03-17T04:48:50.789937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# GLCM + Random Forest pipeline\n",
    "#Gray-Level Co-occurrence Matrix\n",
    "X_train_glcm = extract_glcm_features(X_train)\n",
    "X_test_glcm = extract_glcm_features(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_glcm, y_train)\n",
    "y_pred_rf = rf.predict(X_test_glcm)\n",
    "\n",
    "print(\"\\nRandom Forest with GLCM Features\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf) * 100:.2f}%\")\n"
   ],
   "id": "376ccdf9a86689a5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting GLCM features: 100%|██████████| 2147/2147 [00:03<00:00, 637.91it/s]\n",
      "Extracting GLCM features: 100%|██████████| 537/537 [00:00<00:00, 591.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest with GLCM Features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       321\n",
      "           1       0.79      0.82      0.81       216\n",
      "\n",
      "    accuracy                           0.84       537\n",
      "   macro avg       0.84      0.84      0.84       537\n",
      "weighted avg       0.84      0.84      0.84       537\n",
      "\n",
      "Accuracy: 84.36%\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
